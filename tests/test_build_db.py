import unittest
from unittest.mock import patch, MagicMock, mock_open, PropertyMock
import pathlib
import pandas as pd
import argparse # For creating mock args
from io import StringIO # For mocking file contents for pandas
import tempfile # For temporary files and directories
import gzip # For gzipping test files
import shutil # For copying file objects

# Import the class/functions to be tested
from src.strainr.build_db import DatabaseBuilder
# from src.strainr.utils import open_file_transparently # This is used internally by SeqIO.parse

# Helper function for creating gzipped FASTA files
def create_gzipped_fasta_file(content: str, output_path: pathlib.Path):
    # Ensure parent directory exists
    output_path.parent.mkdir(parents=True, exist_ok=True)
    # Write uncompressed content first
    uncompressed_path = output_path.with_suffix('.tmp_uncompressed')
    with open(uncompressed_path, "w") as f_out:
        f_out.write(content)
    # Gzip the uncompressed file to the target output_path
    with open(uncompressed_path, "rb") as f_in, gzip.open(output_path, "wb") as f_gz_out:
        shutil.copyfileobj(f_in, f_gz_out)
    uncompressed_path.unlink() # Remove the temporary uncompressed file

class TestDatabaseBuilder(unittest.TestCase):

    def setUp(self):
        # Common setup for tests, e.g., creating a mock args namespace
        self.mock_args = argparse.Namespace(
            taxid=None,
            assembly_accessions=None,
            genus=None,
            custom=None,
            kmerlen=5, # Using a small kmerlen for test simplicity
            assembly_levels='complete',
            source='refseq',
            procs=1,
            out='test_db', # This will be prefixed by a temp directory path
            unique_taxid=False
        )
        # Create a temporary directory for outputs generated by DatabaseBuilder instance
        self.test_dir_obj = tempfile.TemporaryDirectory()
        self.test_dir = pathlib.Path(self.test_dir_obj.name)

        # Adjust args to ensure outputs are within the temp_dir
        self.mock_args.out = str(self.test_dir / 'test_db_output_prefix')

        # Patch pathlib.Path.cwd to return our temporary test directory's path
        # This ensures that DatabaseBuilder's default base_path is within our control
        self.cwd_patcher = patch('pathlib.Path.cwd', return_value=self.test_dir)
        self.mock_cwd = self.cwd_patcher.start()

        self.builder = DatabaseBuilder(args=self.mock_args)
        # The DatabaseBuilder's __init__ creates self.output_db_dir.
        # It should now be rooted within self.test_dir due to cwd patching and args.out modification.
        # Example: self.builder.output_db_dir = self.test_dir / (self.mock_args.out + "_files")
        # self.builder.output_db_dir.mkdir(parents=True, exist_ok=True) # This is done in __init__

    def tearDown(self):
        # Stop the patcher
        self.cwd_patcher.stop()
        # Clean up the temporary directory
        self.test_dir_obj.cleanup()

    # Test methods for _parse_assembly_level
    def test_parse_assembly_level_complete(self):
        self.builder.args.assembly_levels = 'complete'
        self.builder.args.assembly_accessions = None # Ensure this is None for this test case
        self.assertEqual(self.builder._parse_assembly_level(), 'complete')

    def test_parse_assembly_level_chromosome(self):
        self.builder.args.assembly_levels = 'chromosome'
        self.builder.args.assembly_accessions = None
        self.assertEqual(self.builder._parse_assembly_level(), 'complete,chromosome')

    def test_parse_assembly_level_scaffold(self):
        self.builder.args.assembly_levels = 'scaffold'
        self.builder.args.assembly_accessions = None
        self.assertEqual(self.builder._parse_assembly_level(), 'complete,chromosome,scaffold')

    def test_parse_assembly_level_contig(self):
        self.builder.args.assembly_levels = 'contig'
        self.builder.args.assembly_accessions = None
        self.assertEqual(self.builder._parse_assembly_level(), 'complete,chromosome,scaffold,contig')
    
    def test_parse_assembly_level_with_accessions(self):
        self.builder.args.assembly_accessions = "some_file.txt" # Value doesn't matter, just its presence
        self.assertEqual(self.builder._parse_assembly_level(), 'all')

    def test_parse_assembly_level_invalid(self):
        self.builder.args.assembly_levels = 'invalid_level'
        self.builder.args.assembly_accessions = None
        with self.assertRaises(ValueError):
            self.builder._parse_assembly_level()

    # Test methods for _extract_strain_name_from_metadata
    def test_extract_strain_name_no_metadata(self):
        mock_genome_file = MagicMock(spec=pathlib.Path)
        # Mocking the .name attribute using PropertyMock for pathlib.Path objects
        type(mock_genome_file).name = PropertyMock(return_value="GCF_000123.1_ASM123v1.fna.gz")
        
        name = self.builder._extract_strain_name_from_metadata(mock_genome_file, None)
        self.assertEqual(name, "GCF_000123.1_ASM123v1")

    def test_extract_strain_name_empty_metadata_df(self):
        mock_genome_file = MagicMock(spec=pathlib.Path)
        type(mock_genome_file).name = PropertyMock(return_value="GCF_000123.1_ASM123v1.fna.gz")
        empty_df = pd.DataFrame()
        
        name = self.builder._extract_strain_name_from_metadata(mock_genome_file, empty_df)
        self.assertEqual(name, "GCF_000123.1_ASM123v1")

    def test_extract_strain_name_metadata_found_full_info(self):
        mock_genome_file = MagicMock(spec=pathlib.Path)
        type(mock_genome_file).name = PropertyMock(return_value="GCF_000123.1_ASM123v1.fna.gz")
        
        metadata_dict = {
            'assembly_accession': ['GCF_000123.1'], # Note: GCF_000123.1 derived from filename
            'organism_name': ['Escherichia coli'],
            'infraspecific_name': ['strain=K12']
        }
        metadata_df = pd.DataFrame(metadata_dict).set_index('assembly_accession')
        
        name = self.builder._extract_strain_name_from_metadata(mock_genome_file, metadata_df)
        self.assertEqual(name, "Escherichia coli strain=K12 (GCF_000123.1)")

    def test_extract_strain_name_metadata_found_no_strain_info(self):
        mock_genome_file = MagicMock(spec=pathlib.Path)
        type(mock_genome_file).name = PropertyMock(return_value="GCF_000456.1_ASM456v1.fna.gz")
        
        metadata_dict = {
            'assembly_accession': ['GCF_000456.1'],
            'organism_name': ['Salmonella enterica'],
            'infraspecific_name': [None] # Could also be pd.NA, float('nan')
        }
        metadata_df = pd.DataFrame(metadata_dict).set_index('assembly_accession')
        
        name = self.builder._extract_strain_name_from_metadata(mock_genome_file, metadata_df)
        self.assertEqual(name, "Salmonella enterica (GCF_000456.1)")

    def test_extract_strain_name_metadata_found_nan_strain_info(self):
        mock_genome_file = MagicMock(spec=pathlib.Path)
        type(mock_genome_file).name = PropertyMock(return_value="GCF_000789.1_ASM789v1.fna.gz")
        
        metadata_dict = {
            'assembly_accession': ['GCF_000789.1'],
            'organism_name': ['Klebsiella pneumoniae'],
            'infraspecific_name': ['nan'] # String "nan"
        }
        metadata_df = pd.DataFrame(metadata_dict).set_index('assembly_accession')
        
        name = self.builder._extract_strain_name_from_metadata(mock_genome_file, metadata_df)
        self.assertEqual(name, "Klebsiella pneumoniae (GCF_000789.1)")

    def test_extract_strain_name_accession_not_in_metadata(self):
        mock_genome_file = MagicMock(spec=pathlib.Path)
        type(mock_genome_file).name = PropertyMock(return_value="GCF_000999.1_ASM999v1.fna.gz")
        
        metadata_dict = { # GCF_000999.1 is not in this list
            'assembly_accession': ['GCF_000111.1'], 
            'organism_name': ['Yersinia pestis'],
            'infraspecific_name': ['strain=CO92']
        }
        metadata_df = pd.DataFrame(metadata_dict).set_index('assembly_accession')
        
        name = self.builder._extract_strain_name_from_metadata(mock_genome_file, metadata_df)
        self.assertEqual(name, "GCF_000999.1_ASM999v1") # Falls back to base name

    # Test methods for _filter_genomes_by_unique_taxid
    @patch('pandas.read_csv')
    def test_filter_genomes_unique_taxid_basic(self, mock_read_csv):
        metadata_content = """assembly_accession,taxid,species_taxid,local_filename
GCA_001,101,100,GCA_001.fna.gz
GCA_002,200,200,GCA_002.fna.gz
GCA_003,301,300,GCA_003.fna.gz
GCA_004,400,,GCA_004.fna.gz
""" # GCA_004 has missing species_taxid, still considered unique if taxid present
        mock_df = pd.read_csv(StringIO(metadata_content))
        mock_read_csv.return_value = mock_df

        genome_dir = self.test_dir / "genomes_filter_test"
        genome_dir.mkdir(exist_ok=True)
        (genome_dir / "GCA_001.fna.gz").touch()
        (genome_dir / "GCA_002.fna.gz").touch() # Filtered out: taxid == species_taxid
        (genome_dir / "GCA_003.fna.gz").touch()
        (genome_dir / "GCA_004.fna.gz").touch() # Kept: taxid present, species_taxid is NaN effectively

        mock_metadata_path = self.test_dir / "metadata_filter.tsv"
        # No need to actually write mock_metadata_path, pandas.read_csv is patched

        # Patch Path.exists for metadata file and genome files
        # And also for the filtered metadata path writing
        def mock_path_exists_filter(path_obj):
            if path_obj == mock_metadata_path: return True
            if path_obj.parent == genome_dir and path_obj.name.endswith(".fna.gz"): return True
            if path_obj.name == f"filtered_{mock_metadata_path.name}": return True # For saving filtered metadata
            return False

        with patch('pathlib.Path.exists', side_effect=mock_path_exists_filter), \
             patch('pandas.DataFrame.to_csv') as mock_to_csv: # Mock to_csv as well
            filtered_files = self.builder._filter_genomes_by_unique_taxid(genome_dir, mock_metadata_path)
        
        self.assertEqual(len(filtered_files), 3)
        self.assertIn(genome_dir / "GCA_001.fna.gz", filtered_files)
        self.assertIn(genome_dir / "GCA_003.fna.gz", filtered_files)
        self.assertIn(genome_dir / "GCA_004.fna.gz", filtered_files)
        mock_to_csv.assert_called_once() # Check that filtered metadata was attempted to be saved

    @patch('pandas.read_csv')
    def test_filter_genomes_metadata_missing_local_filename(self, mock_read_csv):
        metadata_content = """assembly_accession,taxid,species_taxid
GCA_001,101,100
""" # Missing local_filename column
        mock_df = pd.read_csv(StringIO(metadata_content))
        mock_read_csv.return_value = mock_df

        genome_dir = self.test_dir / "genomes_missing_col"
        genome_dir.mkdir(exist_ok=True)
        mock_metadata_path = self.test_dir / "metadata_missing_col.tsv"

        with patch('pathlib.Path.exists', return_value=True), \
             patch('pandas.DataFrame.to_csv'):
            filtered_files = self.builder._filter_genomes_by_unique_taxid(genome_dir, mock_metadata_path)
        self.assertEqual(len(filtered_files), 0) # Should return empty if no local_filename

    @patch('pandas.read_csv')
    def test_filter_genomes_local_file_does_not_exist(self, mock_read_csv):
        metadata_content = """assembly_accession,taxid,species_taxid,local_filename
GCA_001,101,100,non_existent_GCA_001.fna.gz 
""" # local_filename points to a file that won't exist
        mock_df = pd.read_csv(StringIO(metadata_content))
        mock_read_csv.return_value = mock_df

        genome_dir = self.test_dir / "genomes_non_existent_local"
        genome_dir.mkdir(exist_ok=True)
        mock_metadata_path = self.test_dir / "metadata_non_existent_local.tsv"

        # Mock Path.exists: metadata exists, but the genome file does not
        def mock_path_exists_specific(path_obj):
            if path_obj == mock_metadata_path: return True
            if path_obj == (genome_dir / "non_existent_GCA_001.fna.gz"): return False
            return True # Other potential calls
        
        with patch('pathlib.Path.exists', side_effect=mock_path_exists_specific), \
             patch('pandas.DataFrame.to_csv'):
            filtered_files = self.builder._filter_genomes_by_unique_taxid(genome_dir, mock_metadata_path)
        self.assertEqual(len(filtered_files), 0)

    # Test methods for k-mer generation in _process_single_fasta_for_kmers
    # Patch 'open_file_transparently' which is used by SeqIO.parse inside the target function
    @patch('src.strainr.build_db.open_file_transparently', new_callable=mock_open)
    def test_process_single_fasta_for_kmers_writes_correct_kmers(self, mock_actual_open):
        # Setup mock for open_file_transparently to return FASTA content
        # This mock will be used by SeqIO.parse(f_handle, "fasta")
        mock_actual_open.return_value = StringIO(">seq1\nATGCGTAGCATGC\n") # kmerlen is 5 (from setUp)
        
        dummy_fasta_path = self.test_dir / "dummy.fna.gz" # Path doesn't need to exist due to mock_open
        strain_name = "test_strain"
        strain_idx = 0
        
        # Create a real temporary file path within our test_dir for k-mer output
        temp_kmer_file_path = self.test_dir / "kmer_output.txt"
        
        genome_file_info = (dummy_fasta_path, strain_name, strain_idx, temp_kmer_file_path)
        
        # kmer_length is from self.mock_args.kmerlen (set to 5 in setUp)
        # num_total_strains is not critically used by the kmer writing part itself, only for context
        _, _, written_kmer_count, out_path = self.builder._process_single_fasta_for_kmers(
            genome_file_info, 
            kmer_length=self.mock_args.kmerlen, 
            num_total_strains=1 
        )

        self.assertEqual(written_kmer_count, 9)
        self.assertEqual(out_path, temp_kmer_file_path) # Ensure it returns the correct path

        # Read the temporary file and verify its content
        written_kmers = set()
        with open(temp_kmer_file_path, "r", encoding="utf-8") as f:
            for line in f:
                written_kmers.add(line.strip())
        
        expected_kmers_str = {"ATGCG", "TGCGT", "GCGTA", "CGTAG", "GTAGC", "TAGCA", "AGCAT", "GCATG", "CATGC"}
        self.assertEqual(written_kmers, expected_kmers_str)
        
        if temp_kmer_file_path.exists(): # Cleanup this specific file
             temp_kmer_file_path.unlink()

    @patch('src.strainr.build_db.open_file_transparently', new_callable=mock_open)
    def test_process_single_fasta_kmers_seq_shorter_than_kmerlen(self, mock_actual_open):
        mock_actual_open.return_value = StringIO(">seq1\nATG\n") # kmerlen is 5
        
        dummy_fasta_path = self.test_dir / "short.fna.gz"
        temp_kmer_file_path = self.test_dir / "short_kmer_output.txt"
        genome_file_info = (dummy_fasta_path, "short_strain", 0, temp_kmer_file_path)
        
        _, _, written_kmer_count, _ = self.builder._process_single_fasta_for_kmers(
            genome_file_info, kmer_length=self.mock_args.kmerlen, num_total_strains=1
        )
        self.assertEqual(written_kmer_count, 0)
        self.assertTrue(temp_kmer_file_path.exists()) # File should be created
        with open(temp_kmer_file_path, "r") as f:
            self.assertEqual(f.read(), "") # Should be empty

        if temp_kmer_file_path.exists(): temp_kmer_file_path.unlink()

    @patch('src.strainr.build_db.open_file_transparently', new_callable=mock_open)
    def test_process_single_fasta_kmers_seq_equals_kmerlen(self, mock_actual_open):
        mock_actual_open.return_value = StringIO(">seq1\nATGCG\n") # kmerlen is 5
        
        dummy_fasta_path = self.test_dir / "equal.fna.gz"
        temp_kmer_file_path = self.test_dir / "equal_kmer_output.txt"
        genome_file_info = (dummy_fasta_path, "equal_strain", 0, temp_kmer_file_path)
        
        _, _, written_kmer_count, _ = self.builder._process_single_fasta_for_kmers(
            genome_file_info, kmer_length=self.mock_args.kmerlen, num_total_strains=1
        )
        self.assertEqual(written_kmer_count, 1)
        with open(temp_kmer_file_path, "r") as f:
            self.assertEqual(f.read().strip(), "ATGCG")

        if temp_kmer_file_path.exists(): temp_kmer_file_path.unlink()

    # --- Integration Tests for create_database ---

    def test_create_database_custom_genomes(self):
        # 1. Setup: Create custom genome files
        custom_genomes_dir = self.test_dir / "custom_genomes_for_integration"
        custom_genomes_dir.mkdir(parents=True, exist_ok=True)

        fasta_content_strain_a = ">seq1_strainA\nATGCGTAGCATGC\n>seq2_strainA\nAAAAACCCCCGGGGG\n"
        fasta_path_strain_a = custom_genomes_dir / "strainA.fna"
        with open(fasta_path_strain_a, "w") as f:
            f.write(fasta_content_strain_a)

        fasta_content_strain_b = ">seq1_strainB\nTGCATGCATGC\n>seq2_strainB\nGGGGGTTTTTAAAAA\n"
        fasta_path_strain_b_gz = custom_genomes_dir / "strainB.fna.gz"
        create_gzipped_fasta_file(fasta_content_strain_b, fasta_path_strain_b_gz)

        # Configure args for custom genomes
        self.builder.args.custom = str(custom_genomes_dir)
        self.builder.args.taxid = None # Ensure other sources are off
        self.builder.args.genus = None
        self.builder.args.assembly_accessions = None
        self.builder.args.kmerlen = 5 # Consistent with earlier kmer tests

        # 2. Execution
        self.builder.create_database()

        # 3. Verification
        # Check output Parquet file (name derived from self.mock_args.out)
        # self.mock_args.out was "self.test_dir / 'test_db_output_prefix'"
        # So parquet file is "self.test_dir / 'test_db_output_prefix.db.parquet'"
        # DatabaseBuilder prepends base_path which is self.test_dir via cwd_patcher
        # So, expected_db_path = self.test_dir / (self.mock_args.out + ".db.parquet")
        # No, self.builder.base_path is self.test_dir (due to cwd patch)
        # self.builder.output_db_name is self.mock_args.out (which is an absolute path within test_dir)
        # So, output_path = pathlib.Path(self.builder.output_db_name + ".db.parquet")
        
        # The output path logic in DatabaseBuilder is:
        # output_path = self.base_path / (self.output_db_name + ".db.parquet")
        # self.base_path is self.test_dir (mocked cwd)
        # self.output_db_name is self.mock_args.out (e.g. /tmp/xyz/test_db_output_prefix)
        # So output_path is /tmp/xyz/test_db_output_prefix.db.parquet
        # This seems fine.
        expected_db_path = pathlib.Path(self.mock_args.out + ".db.parquet")
        self.assertTrue(expected_db_path.exists(), f"Database Parquet file not found at {expected_db_path}")

        db_df = pd.read_parquet(expected_db_path)

        # Verify dimensions (2 strains, kmerlen=5)
        # Strain A k-mers: ATGCG, TGCGT, GCGTA, CGTAG, GTAGC, TAGCA, AGCAT, GCATG, CATGC (9)
        #                  AAAAA, AAAAC, AAACC, AACCC, ACCCCC, CCCCC, CCCCG, CCGGG, CGGGG, GGGGG (10)
        # Strain B k-mers: TGCAT, GCATG, CATGC, ATgca, TGCat, GCAtg, CATGc (7, 'ATGCATGCATGC')
        #                  GGGGG, GGGGT, GGGTT, GGTTT, GTTTT, TTTTT, TTTTA, TTTAA, TTAAA, TAAAA (10)
        # Shared: TGCAT, GCATG, CATGC, GGGGG
        # Total unique k-mers: 9 (A-seq1) + 10 (A-seq2) + (7-3) (B-seq1 unique) + (10-1) (B-seq2 unique)
        # = 9 + 10 + 4 + 9 = 32
        
        # Let's calculate expected k-mers more carefully
        kmers_a1 = {"ATGCG", "TGCGT", "GCGTA", "CGTAG", "GTAGC", "TAGCA", "AGCAT", "GCATG", "CATGC"}
        kmers_a2 = {"AAAAA", "AAAAC", "AAACC", "AACCC", "ACCCC", "CCCCC", "CCCCG", "CCCGG", "CCGGG", "CGGGG", "GGGGG"} # Corrected ACCCC from ACCCCC
        kmers_b1 = {"TGCAT", "GCATG", "CATGC", "ATGCA", "TGCAT", "GCATG", "CATGC"} # sequence is TGCATGCATGC
        kmers_b2 = {"GGGGG", "GGGGT", "GGGTT", "GGTTT", "GTTTT", "TTTTT", "TTTTA", "TTTAA", "TAAAA", "AAAAA"} # Corrected GGGGGTTTTTAAAAA

        all_kmers = kmers_a1.union(kmers_a2).union(kmers_b1).union(kmers_b2)
        self.assertEqual(db_df.shape[0], len(all_kmers)) # Number of unique k-mers
        self.assertEqual(db_df.shape[1], 2) # Number of strains

        # Verify column names (strain identifiers)
        # Default naming from _get_genome_names_for_files uses filename without extension
        # It also appends _1, _2 if names are duplicated, but here they should be unique.
        expected_strain_names = sorted(["strainA", "strainB"]) # build_db sorts file list, so names might be sorted
        actual_strain_names = sorted(list(db_df.columns))
        self.assertListEqual(actual_strain_names, expected_strain_names)

        # Verify k-mer index (convert to set of strings for comparison)
        db_kmers_set = set(kmer.decode('utf-8') if isinstance(kmer, bytes) else kmer for kmer in db_df.index)
        self.assertEqual(db_kmers_set, all_kmers)

        # Verify specific k-mer presence/absence
        # Kmers are stored as bytes in the dataframe index if they were bytes originally
        # Or strings if they were written as strings and read back. Let's check one as bytes.
        # The k-mers in master_kmer_dict are bytes. Parquet should preserve this.
        
        # Find columns corresponding to strainA and strainB
        col_strain_a = "strainA" if "strainA" in db_df.columns else "strainA_1" # Adjust if names get numbered
        col_strain_b = "strainB" if "strainB" in db_df.columns else "strainB_1"
        if "strainA" not in db_df.columns and "strainA_1" in db_df.columns: # if numbering happens
             col_strain_a = "strainA_1"
             col_strain_b = "strainB_2" # if strainA became strainA_1, strainB might be _2 or just strainB
             # This part needs to be robust to the actual naming from _get_genome_names_for_files
             # For simplicity, assume basic names for now or check actual columns
             if col_strain_a not in db_df.columns: col_strain_a = db_df.columns[0] # Fallback if names are unexpected
             if col_strain_b not in db_df.columns: col_strain_b = db_df.columns[1]


        # ATGCG is unique to strainA (from ATGCGTAGCATGC)
        kmer_atgcg_bytes = b"ATGCG"
        if kmer_atgcg_bytes in db_df.index: # kmer might not be in index if not found
            self.assertTrue(db_df.loc[kmer_atgcg_bytes, col_strain_a])
            self.assertFalse(db_df.loc[kmer_atgcg_bytes, col_strain_b])
        else:
            self.fail(f"Kmer {kmer_atgcg_bytes.decode()} not found in database index")

        # CATGC is in strainA (ATGCGTAGCATGC) and strainB (TGCATGCATGC)
        kmer_catgc_bytes = b"CATGC"
        if kmer_catgc_bytes in db_df.index:
            self.assertTrue(db_df.loc[kmer_catgc_bytes, col_strain_a])
            self.assertTrue(db_df.loc[kmer_catgc_bytes, col_strain_b])
        else:
            self.fail(f"Kmer {kmer_catgc_bytes.decode()} not found in database index")

        # AAAAA is in strainA (AAAAACCCCCGGGGG) and strainB (GGGGGTTTTTAAAAA)
        kmer_aaaaa_bytes = b"AAAAA"
        if kmer_aaaaa_bytes in db_df.index:
            self.assertTrue(db_df.loc[kmer_aaaaa_bytes, col_strain_a])
            self.assertTrue(db_df.loc[kmer_aaaaa_bytes, col_strain_b])
        else:
             self.fail(f"Kmer {kmer_aaaaa_bytes.decode()} not found in database index")

        # CCCCC is unique to strainA (AAAAACCCCCGGGGG)
        kmer_ccccc_bytes = b"CCCCC"
        if kmer_ccccc_bytes in db_df.index:
            self.assertTrue(db_df.loc[kmer_ccccc_bytes, col_strain_a])
            self.assertFalse(db_df.loc[kmer_ccccc_bytes, col_strain_b])
        else:
            self.fail(f"Kmer {kmer_ccccc_bytes.decode()} not found in database index")


    @patch('src.strainr.build_db.ngd.download')
    def test_create_database_ncbi_mocked(self, mock_ngd_download):
        # 1. Setup: Configure args for NCBI download
        self.builder.args.taxid = "12345" # Example taxid
        self.builder.args.custom = None
        self.builder.args.kmerlen = 3 # Keep it simple for this test

        # Define where ncbi-genome-download would place files
        # This path is constructed inside DatabaseBuilder._download_genomes_from_ncbi()
        # output_db_dir / f"ncbi_genomes_{genome_target_dir_suffix}"
        # self.builder.output_db_dir is self.test_dir / (self.mock_args.out + "_files")
        genome_target_dir_suffix = f"s{self.builder.args.taxid}"
        simulated_ncbi_download_dir = self.builder.output_db_dir / f"ncbi_genomes_{genome_target_dir_suffix}"
        simulated_ncbi_download_dir.mkdir(parents=True, exist_ok=True)

        # Create dummy FASTA files that ngd.download would "download"
        fasta_content_ncbi_1 = ">ncbi_strain1_seq1\nATGCGTAG\n"
        fasta_path_ncbi_1_gz = simulated_ncbi_download_dir / "ncbi_strain1.fna.gz"
        create_gzipped_fasta_file(fasta_content_ncbi_1, fasta_path_ncbi_1_gz)

        fasta_content_ncbi_2 = ">ncbi_strain2_seq1\nTAGCATGC\n"
        fasta_path_ncbi_2_gz = simulated_ncbi_download_dir / "ncbi_strain2.fna.gz"
        create_gzipped_fasta_file(fasta_content_ncbi_2, fasta_path_ncbi_2_gz)

        # Create a dummy metadata file that ngd.download would create
        metadata_filename = f"metadata_summary_{genome_target_dir_suffix}.tsv"
        simulated_metadata_path = simulated_ncbi_download_dir / metadata_filename
        metadata_content = (
            "assembly_accession\torganism_name\tinfraspecific_name\ttaxid\tspecies_taxid\tlocal_filename\n"
            "GCA_001\tEscherichia coli\tstrain=ABC\t12345\t562\tncbi_strain1.fna.gz\n"
            "GCA_002\tSalmonella enterica\t\t12345\t28901\tncbi_strain2.fna.gz\n"
        ) # Assuming local_filename is just the basename for flat_output=True
        with open(simulated_metadata_path, "w") as f:
            f.write(metadata_content)

        # Configure the mock for ngd.download
        mock_ngd_download.return_value = 0 # Success

        # (Optional) If unique_taxid filtering is active and complex, consider mocking _filter_genomes_by_unique_taxid
        # For this test, assume unique_taxid is False or metadata is set up to pass it.
        self.builder.args.unique_taxid = False

        # 2. Execution
        self.builder.create_database()

        # 3. Verification
        mock_ngd_download.assert_called_once()
        # Check call args if needed, e.g. mock_ngd_download.assert_called_with(species_taxids="12345", ...)

        expected_db_path = pathlib.Path(self.mock_args.out + ".db.parquet")
        self.assertTrue(expected_db_path.exists(), f"Database Parquet file not found at {expected_db_path}")

        db_df = pd.read_parquet(expected_db_path)

        # Verify dimensions (kmerlen=3)
        # ncbi_strain1 (ATGCGTAG): ATG, TGC, GCG, CGT, GTA, TAG (6 kmers)
        # ncbi_strain2 (TAGCATGC): TAG, AGC, GCA, CAT, ATG, TGC (6 kmers)
        # Shared: ATG, TGC, TAG
        # Unique: 6 + (6-3) = 9
        kmers_ncbi1 = {"ATG", "TGC", "GCG", "CGT", "GTA", "TAG"}
        kmers_ncbi2 = {"TAG", "AGC", "GCA", "CAT", "ATG", "TGC"}
        all_expected_kmers = kmers_ncbi1.union(kmers_ncbi2)

        self.assertEqual(db_df.shape[0], len(all_expected_kmers))
        self.assertEqual(db_df.shape[1], 2) # Two strains

        # Verify column names (derived from metadata)
        # Strain names from _extract_strain_name_from_metadata:
        # GCA_001: "Escherichia coli strain=ABC (GCA_001)"
        # GCA_002: "Salmonella enterica (GCA_002)"
        # These names might be altered if they are too long or contain problematic characters
        # For testing, it's safer to get actual column names and check if they are reasonable
        # or to make mocked names very simple.
        # The _get_genome_names_for_files also sorts the file list before processing.
        # The order of columns in DataFrame might depend on this initial sort of files or processing order.
        
        # For simplicity, let's check if the *number* of columns is right and if some key k-mers are correct.
        # A more robust way would be to mock _get_genome_names_for_files or make metadata simpler.

        # Verify k-mer presence (example)
        kmer_atg_bytes = b"ATG" # Should be in both
        kmer_gcg_bytes = b"GCG" # Should be only in ncbi_strain1
        
        # To make assertions robust to column order/name, find columns by content
        col_strain1, col_strain2 = db_df.columns[0], db_df.columns[1] # Assume order for simplicity for now
        # A better way: identify columns based on a unique kmer if possible, or simplify mocked names.
        # For this example, assume column order [ncbi_strain1, ncbi_strain2] or vice-versa.
        # We can check which column has GCG to identify strain1's column.
        if kmer_gcg_bytes in db_df.index:
            if db_df.loc[kmer_gcg_bytes, db_df.columns[0]]:
                col_strain1 = db_df.columns[0]
                col_strain2 = db_df.columns[1]
            else:
                col_strain1 = db_df.columns[1]
                col_strain2 = db_df.columns[0]

            self.assertTrue(db_df.loc[kmer_atg_bytes, col_strain1])
            self.assertTrue(db_df.loc[kmer_atg_bytes, col_strain2])
            self.assertTrue(db_df.loc[kmer_gcg_bytes, col_strain1])
            self.assertFalse(db_df.loc[kmer_gcg_bytes, col_strain2])
        else:
            self.fail(f"Kmer {kmer_gcg_bytes.decode()} or {kmer_atg_bytes.decode()} not found in db index.")


if __name__ == '__main__':
    unittest.main()
